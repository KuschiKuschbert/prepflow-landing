# Performance Testing Workflow for PrepFlow
# Automated performance testing with Lighthouse CI and budget enforcement

name: Performance Testing

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *' # Daily at 2 AM

jobs:
  performance-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}

      - name: Start application
        run: npm start &
        env:
          PORT: 3000

      - name: Wait for application
        run: npx wait-on http://localhost:3000 --timeout 60000

      - name: Run Lighthouse CI
        run: npx lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Run bundle analysis
        run: npm run analyze
        continue-on-error: true

      - name: Performance budget check
        run: node scripts/check-performance-budget.js
        continue-on-error: true

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: |
            .lighthouseci/
            performance-budget-report.json
            bundle-analysis-report.json

      - name: Comment PR with performance results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Read performance results
            const lighthouseResults = fs.readFileSync('.lighthouseci/results.json', 'utf8');
            const results = JSON.parse(lighthouseResults);

            // Generate performance summary
            let comment = '## ðŸ“Š Performance Test Results\n\n';

            results.forEach(result => {
              const { url, summary } = result;
              comment += `### ${url}\n`;
              comment += `- **Performance Score:** ${summary.performance}\n`;
              comment += `- **Accessibility Score:** ${summary.accessibility}\n`;
              comment += `- **Best Practices Score:** ${summary['best-practices']}\n`;
              comment += `- **SEO Score:** ${summary.seo}\n\n`;
            });

            // Add performance budget status
            if (fs.existsSync('performance-budget-report.json')) {
              const budgetReport = JSON.parse(fs.readFileSync('performance-budget-report.json', 'utf8'));
              comment += `### ðŸš¨ Performance Budget Status\n`;
              comment += `- **Total Violations:** ${budgetReport.totalViolations}\n`;
              comment += `- **Critical Violations:** ${budgetReport.criticalViolations}\n`;
              comment += `- **High Violations:** ${budgetReport.highViolations}\n`;
              comment += `- **Overall Score:** ${budgetReport.score}/100\n\n`;
            }

            // Add bundle analysis
            if (fs.existsSync('bundle-analysis-report.json')) {
              const bundleReport = JSON.parse(fs.readFileSync('bundle-analysis-report.json', 'utf8'));
              comment += `### ðŸ“¦ Bundle Analysis\n`;
              comment += `- **Total Bundle Size:** ${bundleReport.totalSize} bytes\n`;
              comment += `- **JavaScript Size:** ${bundleReport.jsSize} bytes\n`;
              comment += `- **CSS Size:** ${bundleReport.cssSize} bytes\n`;
              comment += `- **Image Size:** ${bundleReport.imageSize} bytes\n\n`;
            }

            // Post comment
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  performance-regression:
    runs-on: ubuntu-latest
    needs: performance-test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download performance results
        uses: actions/download-artifact@v4
        with:
          name: performance-results
          path: ./

      - name: Check for performance regressions
        run: node scripts/check-performance-regression.js
        continue-on-error: true

      - name: Send performance regression alert
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const { execSync } = require('child_process');

            // Send alert to Slack or other notification service
            const webhookUrl = process.env.PERFORMANCE_WEBHOOK_URL;
            if (webhookUrl) {
              const message = {
                text: 'ðŸš¨ Performance Regression Detected',
                blocks: [
                  {
                    type: 'section',
                    text: {
                      type: 'mrkdwn',
                      text: `*Performance Regression Detected*\n\nRepository: ${context.repo.owner}/${context.repo.repo}\nBranch: ${context.ref}\nCommit: ${context.sha}\n\nPlease check the performance test results.`
                    }
                  }
                ]
              };

              execSync(`curl -X POST -H 'Content-type: application/json' --data '${JSON.stringify(message)}' ${webhookUrl}`);
            }

  performance-monitoring:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Start application
        run: npm start &
        env:
          PORT: 3000

      - name: Wait for application
        run: npx wait-on http://localhost:3000 --timeout 60000

      - name: Run comprehensive performance tests
        run: |
          # Run Lighthouse CI
          npx lhci autorun

          # Run bundle analysis
          npm run analyze || echo "Bundle analysis failed, continuing..."

          # Run performance budget check
          node scripts/check-performance-budget.js || echo "Performance budget check failed, continuing..."

          # Generate performance report
          node scripts/generate-performance-report.js || echo "Performance report generation failed, continuing..."

      - name: Upload performance monitoring results
        uses: actions/upload-artifact@v4
        with:
          name: performance-monitoring-$(date +%Y%m%d)
          path: |
            .lighthouseci/
            performance-budget-report.json
            bundle-analysis-report.json
            performance-monitoring-report.json

      - name: Send performance monitoring report
        run: node scripts/send-performance-report.js || echo "Performance report sending failed, continuing..."
        env:
          PERFORMANCE_WEBHOOK_URL: ${{ secrets.PERFORMANCE_WEBHOOK_URL }}
          ALERT_EMAIL_TO: ${{ secrets.ALERT_EMAIL_TO }}
